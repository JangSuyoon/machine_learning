# -*- coding: utf-8 -*-
"""임베디드실습1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jC35CknsGl7ZtaAScS3qfj_U_Rf8SGFp
"""

#import required modules
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.layers import Dense # 완전연결층
from keras.models import Sequential # 레이어를 층층히 쌓아가는 연쇄 모델

"""MNIST 데이터셋은 28x28 사이즈의 손글씨 데이터셋입니다. 0~9까지 총 10개의 클래스를 가지고 있으며, 색상 채널이 없는 흑백 이미지입니다. """

from keras.datasets import mnist # 라이브러리가 기본으로 제공하는 mnist 데이터셋
(X_train, Y_train),(X_test,Y_test)=mnist.load_data()

print("Training data shape : ",X_train.shape)
print("Training label shape : ",Y_train.shape)
print("Testing data shape : ",X_test.shape)
print("Testing label shape : ",Y_test.shape)

#reshape
X_train = X_train.reshape(60000,28*28).astype('float32')
X_test = X_test.reshape(10000,28*28).astype('float32')

#Normalize
X_train = X_train / 255.0
X_test = X_test / 255.0

Y_train = keras.utils.to_categorical(Y_train,10)
Y_test = keras.utils.to_categorical(Y_test,10)

#X_train[0]

model=Sequential() # 모델 선언
#입력 계층
model.add(Dense(units=256,input_dim=(28*28),activation='relu'))
#은닉 계층
model.add(Dense(units=128,activation='relu'))
model.add(Dense(units=64,activation='relu'))
model.add(Dense(units=32,activation='relu'))

#출력 계층
#model.add(Dense(Y_train.shape[1], activation="softmax"))
model.add(Dense(units=10, activation='sigmoid'))
model.summary()

model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])

history = model.fit(X_train,Y_train,batch_size=32,epochs=10,validation_split=0.25,verbose=1)

loss, accuracy = model.evaluate(X_test, Y_test)  # 학습 완료 후 검증
print("손실률:", loss) 
print("정확도:", accuracy)

import matplotlib.pyplot as plt 
plt.figure(figsize=(18, 6))

# 에포크별 정확도
plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="accuracy")
plt.plot(history.history["val_accuracy"], label="val_accuracy")
plt.title("accuracy")
plt.legend()

# 에포크별 손실률
plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="loss")
plt.plot(history.history["val_loss"], label="val_loss")
plt.title("loss")
plt.legend()
plt.ylabel('loss')
plt.xlabel('epoch')

plt.show()





"""CNN을 이용한 MNIST model modify

제가 추가로 해본 모델입니다.
"""

#import required modules
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.layers import Dense # 완전연결층
from keras.models import Sequential # 레이어를 층층히 쌓아가는 연쇄 모델
import keras
from keras.layers import Conv2D, Lambda, MaxPooling2D # convolution layer

from keras.datasets import mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

#데이터 전처리
train_images = train_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))
train_images, test_images = train_images / 255.0, test_images / 255.0

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))

model.summary()

model.add(tf.keras.layers.Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5)

loss, acc = model.evaluate(test_images, test_labels, verbose=2)

"""CNN을 이용한 모델링이 앞선 dense 모델보다 첫번째 epoch부터 낮게 나오고 accuracy도 높게 나오는 것을 알 수 있습니다. 하지만 1개의 epoch 당 시간이 많이 걸리는 것 같습니다."""

